{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import requests\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_text(df):\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    \n",
    "    pattern_month_name = \"January|February|March|April|May|June|July|August|September|October|November|December\"\n",
    "    pattern_month_name_short = \"Jan\\.{0,1}|Feb\\.{0,1}|Mar\\.{0,1}|Apr\\.{0,1}|Aug\\.{0,1}|Sep\\.{0,1}|Oct\\.{0,1}|Nov\\.{0,1}|Dec\\.{0,1}\"\n",
    "\n",
    "    months = pattern_month_name + \"|\" + pattern_month_name_short\n",
    "\n",
    "    pattern_month_number = \"\\d{1,2}\"  # \"[0-1]?[0-9]\"\n",
    "\n",
    "    days = \"\\d{1,2}\"  # \"[0-3]?[0-9]\"\n",
    "\n",
    "    year = \"\\d{2,4}\"\n",
    "\n",
    "    pattern_virus = r\"(rabies|rabies virus)\"\n",
    "\n",
    "    # Patterns\n",
    "\n",
    "    # Catches just XX.XX %\n",
    "    pattern_mort = r\"\\s((mortality rate|CFR|Case Fatality Rate|IFR|infection fatality rate|fatality rate|death rate)\\s.{,40}((below|above)?(?<!\\S)(?=.)([0-9]+|([1-9](\\d*|\\d{0,2}(\\.\\d{3})*)))?(\\.\\d*[1-9])?(\\sper\\scent|\\s{,1}%\\s{,1}))[^–].{,40})\"\n",
    "\n",
    "    # Mortality X to or - or – Y (%)\n",
    "    pattern_mort2 = r\"\\s((mortality rate|CFR|Case Fatality Rate|IFR|infection fatality rate|fatality rate|death rate)\\s.{,40}((below|above)?(?<!\\S)([0-9]{,2}|([1-9](\\d{1}|\\d{0,1}(\\.\\d{3})*)))?(\\.\\d*[1-9])?(\\sto\\s|-|–)([0-9]{,2})?(\\.\\d*)?(%)?).{,40})\"\n",
    "\n",
    "    # XX.XX (per|/ 100,00)\n",
    "    pattern_inc = r\"\\s((incidence|incidence rate)\\s.{,40}((?<!\\S)([0-9]+|([1-9](\\d*|\\d{0,2}(\\.\\d{3})*)))?(\\.\\d*[1-9])?(?!\\S)(/(\\d{1,3},\\d{1,3}|\\d{4})|\\sper\\s(\\d{1,3},\\d{1,3}|\\d{4}))?).{,40})\"\n",
    "\n",
    "    # below|above X\n",
    "    pattern_inc2 = r\"\\s((incidence|incidence rate)\\s.{,40}((below\\s|above\\s)(?<!\\S)([0-9]+|([1-9](\\d*|\\d{0,2}(\\.\\d{3})*)))?(\\.\\d*[1-9])?(?!\\S)(/(\\d{1,3},\\d{1,3}|\\d{4})|\\sper\\s(\\d{1,3},\\d{1,3}|\\d{4}))?).{,40})\"\n",
    "\n",
    "    # XX,XX and|to|- XX,XX (per 100,000)\n",
    "    pattern_inc3 = r\"\\s((incidence|incidence rate)\\s.{,40}((?<!\\S)([0-9]+|([1-9](\\d*|\\d{0,2}(\\.\\d{3})*)))?(\\.\\d*[1-9])?(?!\\S)((\\s-\\s|\\sto\\s|\\sand\\s)(?<!\\S)([0-9]+|([1-9](\\d*|\\d{0,2}(\\.\\d{3})*)))?(\\.\\d*[1-9])?(?!\\S))(/(\\d{1,3},\\d{1,3}|\\d{4})|\\sper\\s(\\d{1,3},\\d{1,3}|\\d{4}))?).{,40})\"\n",
    "\n",
    "    pattern_hospi = r\"\\s((hospitality rate|hospitalization rate)\\s.{,40}((below|above)?(?<!\\S)(?=.)([0-9]+|([1-9](\\d*|\\d{0,2}(\\.\\d{3})*)))?(\\.\\d*[1-9])?%{0,1}(?!\\S)(/(\\d{1,3},\\d{1,3}|\\d{4})|\\sper\\s(\\d{1,3},\\d{1,3}|\\d{4})|\\sof\\s(\\d{1,3},\\d{1,3}|\\d{4}))?).{,40})\"\n",
    "\n",
    "    pattern_r = r\"\\s((r-value|r\\svalue|reproduction value|\\(Rt\\)|reproduction number \\(Rt\\)|Rt|reproduction\\srate|r\\(0\\)\\svalue|r0\\svalue|r-\\(0\\)\\svalue|r0-value)\\s.{,40}((below|above)?(?<!\\S)(?=.)([0-9]+|([1-9](\\d*|\\d{0,2}(,\\d{3})*)))?(\\.\\d*[1-9])?(?!\\S))[^%°]{,40})\"\n",
    "\n",
    "    pattern_r2 = r\"\\s((r-value|r\\svalue|reproduction value|\\(Rt\\)|reproduction number \\(Rt\\)|Rt|reproduction\\srate|r\\(0\\)\\svalue|r0\\svalue|r-\\(0\\)\\svalue|r0-value)\\s.{,40}((below|above)?(?<!\\S)(?=.)([0-9]+|([1-9](\\d*|\\d{0,2}(,\\d{3})*)))?(\\.\\d*[1-9])?(?!\\S)\\s{0,1}(and|-)\\s{0,1}(?<!\\S)(?=.)([0-9]+|([1-9](\\d*|\\d{0,2}(,\\d{3})*)))?(\\.\\d*[1-9])?(?!\\S))[^%°]{,40})\"\n",
    "\n",
    "    pattern_host_1 = \"domestic_dog|canis lupus familiaris|jackal|Canis adustus and C\\. mesomelas|mongoose|Herpestes spp|red fox|Vulpes vulpes|ferret badger|Melogale moschata|golden jackals|Canis aureus|raccoon dog|Nyctereutes procyonoides|raccoon|Procyon lotor|grey fox|Urocyon cinereoargenteus|striped skunk|Mephitis mephitis|coyote|Canis latrans|crab\\-eating fox|Cerdocyon thous|marmoset|Callithrix jacchus|small Indian mongoose|Herpestes auropunctatus|arctic fox|Alopex lagopus\"\n",
    "    \n",
    "    pattern_host_2 = \"transmited by|transfered by|infected by|spreaded by\"\n",
    "    \n",
    "    pattern_host = \"(\" + pattern_host_1 + \"|\" + pattern_host_2 + \")\"\n",
    "    \n",
    "    date_slash = \"(\\d{2,4}/(\\d{1,2}|\" + months + \")/\\d{2,4})\"\n",
    "    date_dot = \"(\\d{2,4}\\.(\\d{1,2}|\" + months + \")\\.\\d{2,4})\"\n",
    "    date_hyphen = \"(\\d{2,4}-(\\d{1,2}|\" + months + \")-\\d{2,4})\"\n",
    "    date_whitespace = \"(\\d{2,4}\\s(\\d{1,2}|\" + months + \")\\s\\d{2,4})\"\n",
    "\n",
    "    # 10/10/2020 aber auch 10/October/2020 aber auch 10/Oct/2020\n",
    "    # 10.10.2020 aber auch 10.October.2020 aber auch 10.Oct.2020\n",
    "    # 10-10-2020 aber auch 10-October-2020 aber auch 10-Oct-2020\n",
    "    # 10 10 2020 aber auch 10 October 2020 aber auch 10 Oct 2020\n",
    "\n",
    "    date_slash_na = \"((\\d{2,4}|\" + months + \")/\\d{1,2}/\\d{2,4})\"\n",
    "    date_dot_na = \"((\\d{2,4}|\" + months + \")\\.\\d{1,2}\\.\\d{2,4})\"\n",
    "    date_hyphen_na = \"((\\d{2,4}|\" + months + \")-\\d{1,2}-\\d{2,4})\"\n",
    "    date_whitespace_na = \"((\\d{2,4}|\" + months + \")\\s\\d{1,2}\\s\\d{2,4})\"\n",
    "\n",
    "    # 10/10/2020 aber auch October/10/2020 aber auch Oct/10/2020\n",
    "    # 10.10.2020 aber auch October.10.2020 aber auch Oct.10.2020\n",
    "    # 10-10-2020 aber auch October-10-2020 aber auch Oct-10-2020\n",
    "    # 10 10 2020 aber auch October 10 2020 aber auch Oct 10 2020\n",
    "\n",
    "    month_day_year = \"(\" + \"(\" + months + \")\" + \"\\s\" + days + \"\\s,\" + year + \")\"\n",
    "    month_year = \"(\" + \"(\" + months + \")\" + \"\\s\" + year + \")\"\n",
    "\n",
    "    date = month_day_year + \"|\" + month_year + \"|\" + date_slash + \"|\" + date_slash_na + \"|\" + date_dot + \"|\" + date_dot_na + \"|\" + date_hyphen + \"|\" + date_hyphen_na + \"|\" + date_whitespace + \"|\" + date_whitespace_na\n",
    "\n",
    "    # range1 = December 14, 2020-January 18, 2021\n",
    "    range1 = \"(\" + \"(\" + months + \")\" + \"\\s\" + days + \",\\s\" + year + \"-\" + \"(\" + months + \")\" + \"\\s\" + days + \",\\s\" + year + \")\"\n",
    "\n",
    "    # range2 = January 2020 to 24 February 2020\n",
    "    range2 = \"(\" + \"(\" + months + \")\" + \"\\s\" + year + \"\\sto\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \")\"\n",
    "\n",
    "    # range3 = Between February 27 and July 22, 2021\n",
    "    range3 = \"(\" + \"Between\" + \"\\s\" + \"(\" + months + \")\" + \"\\s\" + days + \"\\sand\\s\" + \"(\" + months + \")\" + \"\\s\" + days + \",\\s\" + year + \")\"\n",
    "\n",
    "    # range4 = between 1 April 2021 and 30 April 2021\n",
    "    range4 = \"(\" + \"Between\" + \"\\s\" + days + \"\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \"\\sand\\s\" + days + \"\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \")\"\n",
    "\n",
    "    # range5 = 02 March to 30 May 2021\n",
    "    range5 = \"(\" + days + \"\\s\" + \"(\" + months + \")\" + \"\\sto\\s\" + days + \"\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \")\"\n",
    "\n",
    "    # range6 = between 29/01/2021–23/02/2021\n",
    "    range6 = \"(\" + \"Between\" + \"\\s\" + days + \"/\" + pattern_month_number + \"/\" + year + \"-\" + days + \"/\" + pattern_month_number + \"/\" + year + \")\"\n",
    "\n",
    "    # range7 = Q1-Q4 2020\n",
    "    range7 = \"(\" + \"Q[1-4]-Q[1-4]\\s\" + year + \")\"\n",
    "\n",
    "    # range8 = 1 January 2020 to 31 May 2020\n",
    "    range8 = \"(\" + days + \"\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \"\\sto\\s\" + days + \"\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \")\"\n",
    "\n",
    "    # range9 = from March 2020 to June 2021\n",
    "    range9 = \"(\" + \"From\" + \"\\s\" + \"(\" + months + \")\" + \"\\sto\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \")\"\n",
    "\n",
    "    # range10 = between 8 and 27 May 2020\n",
    "    range10 = \"(\" + \"Between\" + \"\\s\" + days + \"\\sand\\s\" + days + \"\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \")\"\n",
    "\n",
    "    # range11 = Between the end of January until the end of February 2021\n",
    "    range11 = \"(\" + \"Between the end of\" + \"\\s\" + \"(\" + months + \")\" + \"\\suntil the end of\\s\" + \"(\" + months + \")\" + \"\\s\" + year + \")\"\n",
    "\n",
    "    # range12 = beginning of 2021\n",
    "    range12 = \"(\" + \"Beginning\" + \"\\sof\\s\" + year + \")\"\n",
    "    # range13 = From October 2020 onwards\n",
    "    range13 = \"(\" + \"From\\s\" + \"(\" + months + \")\\s\" + year + \"\\sonwards\" + \")\"\n",
    "    # range14 = Up to April 2021\n",
    "    range14 = \"(\" + \"Up to\\s\" + \"(\" + months + \")\\s\" + year + \")\"\n",
    "\n",
    "    # range15 = from January 1, 2020 to July 19, 2021\n",
    "    range15 = \"(\" + \"From\" + \"\\s\" + \"(\" + months + \")\\s\" + days + \",\\s\" + year + \"\\sto\\s\" + \"(\" + months + \")\" + \"\\s\" + days + \",\\s\" + year + \")\"\n",
    "\n",
    "    # range16 Februar 4, 2021 through Februar 22, 2021\n",
    "    range16 = \"(\" + \"(\" + months + \")\" + \"\\s\" + days + \"\\s,\" + year + \"\\sthrough\\s\" + \"(\" + months + \")\" + \"\\s\" + days + \"\\s,\" + year + \")\"\n",
    "\n",
    "    range_pattern = \"(\" + range1 + \"|\" + range2 + \"|\" + range3 + \"|\" + range4 + \"|\" + range5 + \"|\" + range6 + \"|\" + range7 + \"|\" + range8 + \"|\" + range9 + \"|\" + range10 + \"|\" + range11 + \"|\" + range12 + \"|\" + range13 + \"|\" + range14 + \"|\" + range15 + \"|\" + range16 + \")\"\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # set capture groups for the pattern\n",
    "    capture_list = [0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0]\n",
    "    \n",
    "    # set name of labels for RegEx pattern\n",
    "    label = [\"DATE_2_range\", \"VIRUS\", \"DATE_2\", \"RVALUE\", \"RVALUE\", \"MORTALITY\", \"MORTALITY\", \"INCIDENCE\", \"INCIDENCE\",\n",
    "             \"INCIDENCE\", \"HOSPITALIZATION\", \"HOST\"]\n",
    "\n",
    "    patterns = [range_pattern, pattern_virus, date, pattern_r, pattern_r2, pattern_mort, pattern_mort2, pattern_inc,\n",
    "                pattern_inc2, pattern_inc3, pattern_hospi, pattern_host]\n",
    "    \n",
    "    # set the labels for spaCy\n",
    "    spacy_labels = [\"GPE\", \"LOC\"]\n",
    "\n",
    "    \n",
    "\n",
    "    # specifiy which patterns should be caught case sensitive\n",
    "    case_sensitive = [True, True, True, True, True, True, True, True, True, True, True, False]\n",
    "    \n",
    "    #load spaCy model\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # start labeling process\n",
    "    \n",
    "    liste_dicts = []\n",
    "    for i, j in tqdm(df.iterrows(), desc=\"Iterate Dataframe\"):\n",
    "        if type(j[\"text\"]) == str:\n",
    "            test = re.split(r'\\.\\s+', j[\"text\"])\n",
    "            # liste_label = []\n",
    "            for k in range(len(test)):\n",
    "                dicti = {}\n",
    "                liste_label = []\n",
    "                liste_date = []\n",
    "                liste_range = []\n",
    "                list_pure_label = []\n",
    "                string1 = test[k]\n",
    "                # take the sentence with the two following sentences\n",
    "                try:\n",
    "                    string = string1 + \". \" + test[k + 1] + \". \" + test[k + 2] + \".\"\n",
    "                # try except to cover setences that dont have previous sentences\n",
    "                except:\n",
    "                    try:\n",
    "                        string = string1 + \". \" + test[k + 1] + \".\"\n",
    "                    except:\n",
    "                        string = string1 + \".\"\n",
    "\n",
    "                for p in range(len(patterns)):\n",
    "                    \n",
    "                    # match the RegEx patterns and apend the sentences and labels into their lists\n",
    "                    \n",
    "                    if case_sensitive[p] == True:\n",
    "                        if re.finditer(patterns[p], string1, flags=re.I):\n",
    "                            hit = re.finditer(patterns[p], string, flags=re.I)\n",
    "                            for y in hit:\n",
    "                                if label[p] != \"DATE_2\" and label[p] != \"DATE_2_range\":\n",
    "                                    liste_label.append(\n",
    "                                        [y.span(capture_list[p])[0], y.span(capture_list[p])[1], label[p]])\n",
    "                                if label[p] != \"DATE_2\" and label[p] != \"VIRUS\" and label[p] != \"DATE_2_range\":\n",
    "                                    list_pure_label.append(label[p])\n",
    "                                if label[p] == \"DATE_2\":\n",
    "                                    liste_date.append(\n",
    "                                        [y.span(capture_list[p])[0], y.span(capture_list[p])[1], label[p]])\n",
    "                                if label[p] == \"DATE_2_range\":\n",
    "                                    liste_range.append(\n",
    "                                        [y.span(capture_list[p])[0], y.span(capture_list[p])[1], label[p]])\n",
    "\n",
    "                    elif case_sensitive[p] == False:\n",
    "                        if re.finditer(patterns[p], string1):\n",
    "                            hit = re.finditer(patterns[p], string)\n",
    "                            for y in hit:\n",
    "                                if label[p] != \"DATE_2\" and label[p] != \"DATE_2_range\":\n",
    "                                    liste_label.append(\n",
    "                                        [y.span(capture_list[p])[0], y.span(capture_list[p])[1], label[p]])\n",
    "                                if label[p] != \"DATE_2\" and label[p] != \"VIRUS\" and label[p] != \"DATE_2_range\":\n",
    "                                    list_pure_label.append(label[p])\n",
    "                                if label[p] == \"DATE_2\":\n",
    "                                    liste_date.append(\n",
    "                                        [y.span(capture_list[p])[0], y.span(capture_list[p])[1], label[p]])\n",
    "                                if label[p] == \"DATE_2_range\":\n",
    "                                    liste_range.append(\n",
    "                                        [y.span(capture_list[p])[0], y.span(capture_list[p])[1], label[p]])\n",
    "                # append the entities found with spaCy to the label_list\n",
    "                ents = nlp(string)\n",
    "\n",
    "                for token in ents.ents:\n",
    "                    if token.label_ in spacy_labels:\n",
    "                        liste_label.append([token.start_char, token.end_char, token.label_])\n",
    "                \n",
    "                # delete the smaller date that was caught, because they were colliding\n",
    "                \n",
    "                index_list = []\n",
    "                for range_label in range(len(liste_range)):\n",
    "                    index_list_2 = []\n",
    "                    for date_label in range(len(liste_date)):\n",
    "                        if liste_range[range_label][0] == liste_date[date_label][0] and liste_range[range_label][1] > \\\n",
    "                                liste_date[date_label][1]:\n",
    "                            index_list_2.append(date_label)\n",
    "                        elif liste_range[range_label][0] < liste_date[date_label][0] and liste_range[range_label][1] == \\\n",
    "                                liste_date[date_label][1]:\n",
    "                            index_list_2.append(date_label)\n",
    "                        elif liste_range[range_label][0] < liste_date[date_label][0] and liste_range[range_label][1] > \\\n",
    "                                liste_date[date_label][1]:\n",
    "                            index_list_2.append(date_label)\n",
    "                    index_list.append(index_list_2)\n",
    "\n",
    "                flat_list = [item for sublist in index_list for item in sublist]\n",
    "\n",
    "                for index in range(len(liste_date)):\n",
    "                    if index not in flat_list:\n",
    "                        liste_range.append(liste_date[index])\n",
    "\n",
    "                liste_label = liste_range + liste_label\n",
    "                \n",
    "                # unify the name of the date labels\n",
    "                for labelx in liste_label:\n",
    "                    if labelx[2] == \"DATE_2_range\":\n",
    "                        labelx[2] = \"DATE_2\"\n",
    "                # create dictionary and keep the entries if they have more than 0 labels\n",
    "                \n",
    "                dicti[\"text\"] = string\n",
    "                dicti[\"label\"] = liste_label\n",
    "                dicti[\"PMCID\"] = j[\"PMCID\"]\n",
    "                dicti[\"Full_author\"] = j[\"FAU\"]\n",
    "                dicti[\"Author\"] = j[\"AU\"]\n",
    "                dicti[\"Author_ID\"] = j[\"AUID\"]\n",
    "\n",
    "                if len(set(list_pure_label)) > 0:\n",
    "                    liste_dicts.append(dicti)\n",
    "\n",
    "    return liste_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/path/to/dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = annotate_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(folder_list):\n",
    "        if not os.path.exists(\"../articles/\"+i):\n",
    "            os.makedirs(\"../articles/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonl_file(liste_dicts, filename):\n",
    "    # create folder\n",
    "    if not os.path.exists(\"../labeled_docs\"):\n",
    "            os.makedirs(\"../labeled_docs\")\n",
    "    # create jsonl file      \n",
    "    output_file = open(\"../labeled_docs\"+\"/\"+filename+\".jsonl\", 'w', encoding='utf-8')\n",
    "    \n",
    "    # write the lines of the jsonl file, each dict is written into a line\n",
    "    \n",
    "    for dic in liste_dicts:\n",
    "        json.dump(dic, output_file)\n",
    "        output_file.write(\"\\n\")\n",
    "\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_jsonl_file(annotations,\"labeled_data_with_spacy_1k\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
